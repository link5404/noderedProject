<script type="text/javascript">
    RED.nodes.registerType('spark-collect', {
        category: 'spark',
        color: '#E6E0F8',
        defaults: {
            name: { value: "" },
            collectTable: { value: "", required: true }
        },
        inputs: 1,
        outputs: 1,
        icon: "collect.png",
        label: function() {
            return this.name || "spark-collect";
        },
        paletteLabel: "collect",
        oneditprepare: function() {
            // Optional: Add any initialization code for your edit dialog here
        }
    });
</script>

<script type="text/html" data-template-name="spark-collect">
    <div class="form-row">
        <p>This will print the rdd</p>
    </div>
    <div class="form-row">
        <label for="node-input-collectTable"><i class="fa fa-table"></i> Table Name</label>
        <input type="text" id="node-input-collectTable" placeholder="e.g: airports_data.csv">
    </div>
</script>

<script type="text/html" data-help-name="spark-collect">
    <p>A node that adds a collect operation to Spark operations JSON.</p>
    <p>This node appends a collect method to the "Methods" array in the message payload.</p>
    <h3>Inputs</h3>
    <dl class="message-properties">
        <dt>payload<span class="property-type">object</span></dt>
        <dd>The JSON object containing a "Methods" array to which the collect operation will be added.</dd>
    </dl>
    <h3>Outputs</h3>
    <dl class="message-properties">
        <dt>payload<span class="property-type">object</span></dt>
        <dd>The modified JSON object with the collect operation added to the "Methods" array.</dd>
    </dl>
    <h3>Details</h3>
    <p>Use this node to add collecting criteria to your Spark operations. The collect expression should be a valid condition that will be translated to a Spark collect operation.</p>
    <p>Specify the table name on which the collect should be applied. This should match one of the table names in your available Tables.</p>
</script>